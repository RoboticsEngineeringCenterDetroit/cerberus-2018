// RobotBuilder Version: 1.5
//
// This file was generated by RobotBuilder. It contains sections of
// code that are automatically generated and assigned by robotbuilder.
// These sections will be updated in the future when you export to
// Java from RobotBuilder. Do not put any code or make any change in
// the blocks indicating autogenerated code or it will be lost on an
// update. Deleting the comments indicating the section will prevent
// it from being updated in the future.


package org.usfirst.frc5577.GearsBot;

import java.util.Comparator;
import java.util.Vector;

import edu.wpi.cscore.CvSink;
import edu.wpi.cscore.CvSource;
import edu.wpi.cscore.UsbCamera;
import edu.wpi.first.wpilibj.CameraServer;
import edu.wpi.first.wpilibj.IterativeRobot;
import edu.wpi.first.wpilibj.Timer;
import edu.wpi.first.wpilibj.command.Command;
import edu.wpi.first.wpilibj.command.CommandGroup;
import edu.wpi.first.wpilibj.command.Scheduler;
import edu.wpi.first.wpilibj.livewindow.LiveWindow;
import edu.wpi.first.wpilibj.smartdashboard.SendableChooser;
import edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;
import edu.wpi.first.wpilibj.vision.VisionThread;

import org.opencv.core.Mat;
import org.opencv.core.Rect;
import org.opencv.imgproc.Imgproc;
import org.usfirst.frc5577.GearsBot.commands.*;
import org.usfirst.frc5577.GearsBot.subsystems.*;

import com.analog.frc.ADIS16448_IMU;
import com.analog.frc.ADXRS453Gyro;

import vision.GripPipeline;

 
/**
 * The VM is configured to automatically run this class, and to call the
 * functions corresponding to each mode, as described in the IterativeRobot
 * documentation. If you change the name of this class or the package after
 * creating this project, you must also update the manifest file in the resource
 * directory.
 */
public class Robot extends IterativeRobot {

    Command autonomousCommand;
    SendableChooser<CommandGroup> autoChooser;

    public static OI oi;
    
    // Subsystems and Hardware
    public static DriveTrain driveTrain;
    public static Blender blender;
    public static Intake intake;
    public static Shooter shooter;
    public static Climber climber;
    public static ShooterGate shooterGate;
    public static ADIS16448_IMU imu;
    public static ADXRS453Gyro gyro;
    public static Pneumatics pneumatics;
    public static Lift lift;
    public static Hook hook;
    
    // Camera and Vision
    public static CameraServer cameraServer1;
    public static CameraServer cameraServer2;
    private static final int IMG_WIDTH = 320;
    private static final int IMG_HEIGHT = 240;

    /**
     * This function is run when the robot is first started up and should be
     * used for any initialization code.
     */
    public void robotInit() {
        RobotMap.init();
        
        driveTrain = new DriveTrain();
        shooter = new Shooter();
        intake = new Intake();
        blender = new Blender();
        climber = new Climber();
        shooterGate = new ShooterGate();
        imu = new ADIS16448_IMU();
        gyro = new ADXRS453Gyro();
        pneumatics = new Pneumatics();
        lift = new Lift();
        hook = new Hook();
        autoChooser = new SendableChooser<CommandGroup>();
        autoChooser.addDefault("Default program", new AutonDriveStraight());
        autoChooser.addObject("Left", new AutonDriveFromLeft());
        autoChooser.addObject("Center", new AutonDriveFromCenter());
        autoChooser.addObject("Right", new AutonDriveFromRight());
        SmartDashboard.putData("Autonomous mode chooser", autoChooser);    

            // OI must be constructed after subsystems. If the OI creates Commands 
            //(which it very likely will), subsystems are not guaranteed to be 
            // constructed yet. Thus, their requires() statements may grab null 
            // pointers. Bad news. Don't move it.
        oi = new OI();
            
            
//            CameraServer.getInstance().startAutomaticCapture(0);
            
            // Set up camera
//            new Thread(() -> {
//            cameraServer1 = CameraServer.getInstance();
//            cameraServer2 = CameraServer.getInstance();
        
        // TODO: TODO: TODO: Please uncomment for seeing the camera view.
//        UsbCamera camera0 = CameraServer.getInstance().startAutomaticCapture(0);
//            UsbCamera camera1 = CameraServer.getInstance().startAutomaticCapture(1);
//        camera0.setResolution(IMG_WIDTH, IMG_HEIGHT);
        }
    
    
    //************************************************************************************************************************************************************************
    //A structure to hold measurements of a pa;rticle
	public class ParticleReport implements Comparator<ParticleReport>, Comparable<ParticleReport>{
		double PercentAreaToImageArea;
		double Area;
		double ConvexHullArea;
		double BoundingRectLeft;
		double BoundingRectTop;
		double BoundingRectRight;
		double BoundingRectBottom;
		
		public int compareTo(ParticleReport r)
		{
			return (int)(r.Area - this.Area);
		}
		
		public int compare(ParticleReport r1, ParticleReport r2)
		{
			return (int)(r1.Area - r2.Area);
		}
	};

	
 //************************************************************************************************************************************************************************
    
    public void autonomous() {
    	
	}

    /**
     * This function is called when the disabled button is hit.
     * You can use it to reset subsystems before shutting down.
     */
    public void disabledInit(){

    }

    public void disabledPeriodic() {
        Scheduler.getInstance().run();
    }

    public void autonomousInit() { 
    	    autonomousCommand = (Command)autoChooser.getSelected();
        // schedule the autonomous command (example)
        if (autonomousCommand != null) 
        	autonomousCommand.start();
        
    }

    /**
     * This function is called periodically during autonomous
     */
    public void autonomousPeriodic() {
        Scheduler.getInstance().run();
        
//        reportContours();
    }

    public void teleopInit() {
        // This makes sure that the autonomous stops running when
        // teleop starts running. If you want the autonomous to 
        // continue until interrupted by another command, remove
        // this line or comment it out.
        if (autonomousCommand != null) 
        	autonomousCommand.cancel();
    }

    /**
     * This function is called periodically during operator control
     */
    public void teleopPeriodic() {
        Scheduler.getInstance().run();
        
//        reportContours();
//        
//        System.out.println("Right wheel encoder count: " + RobotMap.rightWheelEncoder.get());
//        System.out.println("Right wheel encoder distance traveled: " + RobotMap.rightWheelEncoder.getDistance());
    }

    /**
     * This function is called periodically during test mode
     */
    public void testPeriodic() {
//        LiveWindow.run();
    }
    
    public void operatorControl() {
		while(isOperatorControl() && isEnabled()) {
			SmartDashboard.putData("IMU", imu);
			Timer.delay(0.005);				// wait for a motor update time
		}
	}

	//Comparator function for sorting particles. Returns true if particle 1 is larger
	static boolean CompareParticleSizes(ParticleReport particle1, ParticleReport particle2)
	{
		//we want descending sort order
		return particle1.PercentAreaToImageArea > particle2.PercentAreaToImageArea;
	}
	


	/**
	 * Converts a ratio with ideal value of 1 to a score. The resulting function is piecewise
	 * linear going from (0,0) to (1,100) to (2,0) and is 0 for all inputs outside the range 0-2
	 */
	double ratioToScore(double ratio)
	{
		return (Math.max(0, Math.min(100*(1-Math.abs(1-ratio)), 100)));
	}

	/**
	 * Method to score convex hull area. This scores how "complete" the particle is. Particles with large holes will score worse than a filled in shape
	 */
	double ConvexHullAreaScore(ParticleReport report)
	{
		return ratioToScore((report.Area/report.ConvexHullArea)*1.18);
	}

	/**
	 * Method to score if the particle appears to be a trapezoid. Compares the convex hull (filled in) area to the area of the bounding box.
	 * The expectation is that the convex hull area is about 95.4% of the bounding box area for an ideal tote.
	 */
	double TrapezoidScore(ParticleReport report)
	{
		return ratioToScore(report.ConvexHullArea/((report.BoundingRectRight-report.BoundingRectLeft)*(report.BoundingRectBottom-report.BoundingRectTop)*.954));
	}

	/**
	 * Method to score if the aspect ratio of the particle appears to match the long side of a tote.
	 */
	/*
	double LongSideScore(ParticleReport report)
	{
		return ratioToScore(((report.BoundingRectRight-report.BoundingRectLeft)/(report.BoundingRectBottom-report.BoundingRectTop))/LONG_RATIO);
	}
	
	*/

	/**
	 * Method to score if the aspect ratio of the particle appears to match the short side of a tote.
	 */
	/*
	double ShortSideScore(ParticleReport report){
		return ratioToScore(((report.BoundingRectRight-report.BoundingRectLeft)/(report.BoundingRectBottom-report.BoundingRectTop))/SHORT_RATIO);
	}
	
	*/

	/**
	 * Computes the estimated distance to a target using the width of the particle in the image. For more information and graphics
	 * showing the math behind this approach see the Vision Processing section of the ScreenStepsLive documentation.
	 *
	 * @param image The image to use for measuring the particle estimated rectangle
	 * @param report The Particle Analysis Report for the particle
	 * @param isLong Boolean indicating if the target is believed to be the long side of a tote
	 * @return The estimated distance to the target in feet.
	 */
	
	/*
	double computeDistance (Image image, ParticleReport report, boolean isLong) {
		double normalizedWidth, targetWidth;
		NIVision.GetImageSizeResult size;

		size = NIVision.imaqGetImageSize(image);
		normalizedWidth = 2*(report.BoundingRectRight - report.BoundingRectLeft)/size.width;
		targetWidth = isLong ? 26.0 : 16.9;

		return  targetWidth/(normalizedWidth*12*Math.tan(VIEW_ANGLE*Math.PI/(180*2)));
	}
	*/
	
}
